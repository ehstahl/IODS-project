#Week 6: Analysis of longitudinal data
---

Import all necessary libraries.

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
```

Import the RATS data and display it.

```{r}
RATS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt", sep='\t', header=TRUE)
RATS
```

The set comprises of 16 rats divided into 3 different groups, depending on the diet they were put on. The table shows the weight development for each rat (each figure is weight at that time in grams).

Next we draw the plot for this set, differentiating between the diet groups. But before that we need to convert the set into long form.

```{r}
RATS$ID <- factor(RATS$ID)
RATS$Group <- factor(RATS$Group)

RATSL <- RATS %>% gather(key = WD, value = Weight, -ID, -Group) %>% mutate(Time = as.integer(substr(WD, 3, 4)))
```

And now we draw the plot, with the set in long form.

```{r}
ggplot(RATSL, aes(x = Time, y = Weight, linetype = ID)) +
  geom_line() +
  xlab("Days") +
  ylab("Weight in grams") +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ Group, labeller = label_both) +
  theme(legend.position = "none")
```

As we can see, there individuals start out with vastly different weights. In general the rats in the first group weigh half as much as the ones in 2 and 3. The rats in group 2 clearly gain the most weight, group 3 almost as much, but the ones in 1 gain almost no weight.

This following of progress in individuals over time, also known as tracking, can be done better with standardized data. So next, we standardize the rat data and plot it.

```{r}
RATSL <- RATSL %>%
  group_by(Time) %>%
  mutate(stdw = scale(Weight)) %>%
  ungroup()

ggplot(RATSL, aes(x = Time, y = stdw, linetype = ID)) +
  geom_line() +
  xlab("Days") +
  ylab("Standardized weight in grams") +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ Group, labeller = label_both) +
  theme(legend.position = "none")
```

Now that we've subtracted the weight mean from the observations and divided by the standard deviation a completely different plot presents itself. By creating average profiles of each group, this method can iron out some larger differences that cause the plot to skew. In the difference here between the first and the second plot, there's some indication of perhaps an outlier or something similar, that throws the first plot off balance. The difference is stark especially when looking at the coefficients of the lines, with more or less everyone going from weight gain in the first plot to neutral weight or even weight loss in the second plot.

As mentioned in the MABS-book, boxplot-like (summary graphs) plots can be good to spot for example potential outliers. So next, we move on to that.

```{r}
n <- RATSL$Time %>% unique() %>% length()

RATSS <- RATSL %>%
  group_by(Group, Time) %>%
  summarise(mean = mean(Weight), se = (sd(Weight)/sqrt(n))) %>%
  ungroup()

glimpse(RATSS)

ggplot(RATSS, aes(x = Time, y = mean, linetype = Group, shape = Group)) +
  geom_line() +
  scale_linetype_manual(values = c(1,2,3)) +
  geom_point(size=3) +
  scale_shape_manual(values = c(1,2,3)) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se, linetype="1"), width=0.3) +
  theme(legend.position = c(0.8,0.45)) +
  scale_y_continuous(name = "mean(Weight) +/- se(Weight)") +
  scale_x_continuous(name = "Days")
```

Here we use mean weight profiles again with standard errors subtracted from them, which is quite indicative of the lines behaving this coherently. Worth noting though that here again the general trend has shifted towards weight gain.

For the next boxplot I've wasted hours on trying to get it to work correctly, but I just can't get the three groups to appear grouped on each x-value. Below my failed work in progress.

```{r}
ggplot(RATSL, aes(Time,Weight)) +
  geom_boxplot(aes(fill=Group)) +
  scale_x_continuous(name = "Week", breaks = seq(1, 70, 7))
```

Next we create boxplots with weight means over the course of the handful of weeks of the experiment. We exclude the first week by filtering (Time > 1).

```{r}
RATSLS <- RATSL %>%
  filter(Time > 1) %>%
  group_by(Group, ID) %>%
  summarise( mean=mean(Weight) ) %>%
  ungroup()

glimpse(RATSLS)

ggplot(RATSLS, aes(x = Group, y = mean)) +
  geom_boxplot() +
  stat_summary(fun.y = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(Weight), first week excluded")
```

As we the plot shows, individuals in group 1 and 3 have quite similar weight means over the course of the experiment.

In group 2 on the other hand there's a clear outlier, so we discard that one by filtering (mean < 550) and plot again.

```{r}
RATSLS <- RATSL %>%
  filter(Time > 1, Weight < 550) %>%
  group_by(Group, ID) %>%
  summarise( mean=mean(Weight) ) %>%
  ungroup()

glimpse(RATSLS)

ggplot(RATSLS, aes(x = Group, y = mean)) +
  geom_boxplot() +
  stat_summary(fun.y = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(Weight), first week excluded")
```

As the plot shows, removing that outlier made the span in Group 2 significantly more coherent. With the outlier the second and third quartile spanned from around 450 grams to almost 500. But without the outlier, the group is tightly gathered around 450 grams. The visuals of group 3 shifted a bit, but that's just because the scale of the y-axis shifted due to the discarding of the high value in group 2.

On to t-tests.

Rstudio completely refused to take my code on the t-tests citing problem after problem, so the part on the t-test is accounted for below in plain text.

Using the same set as above (with the outlier removed) to do a t-test and inspect evidence of a group difference.

RATSLS <- RATSL %>%
  filter(Time > 1, Weight < 550) %>%
  group_by(Group, ID) %>%
  summarise( mean=mean(Weight) ) %>%
  ungroup()

t.test(mean, Group, data = RATSLS, var.equal = TRUE)

Next we add the baseline (day zero, so to speak, before the beginning of the experiment) to the covariance analysis.

RATSLS2 <- RATSLS %>%
  mutate(baseline = RATS$WD1)

Then we fit the linear model with the mean weight as response and the initial weight and diet group as explanatories.

fit <- lm(mean ~ baseline + Group, data = RATSLS2)

Lastly we have a look at the variance table for the fitted model.

anova(fit)


Moving on to the second part, with analysis of the BPRS data. Next we'll import it and view it in its original wide form and then in long form.

```{r}
BPRS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/BPRS.txt", sep=" ", header=TRUE)

glimpse(BPRS)

BPRS$treatment <- factor(BPRS$treatment)
BPRS$subject <- factor(BPRS$subject)

BPRSL <-  BPRS %>% gather(key = weeks, value = bprs, -treatment, -subject)
BPRSL <-  BPRSL %>% mutate(week = as.integer(substr(weeks, 5, 5)))

glimpse(BPRSL)
```

BPRS comprises of test persons psychiatric evaluation scores over 9 weeks.
In the BPRS-set the weeks can be grouped into a single column, which only uses a digit to identify said week. Above that has been done in the process to convert the set into long form.

```{r}
ggplot(BPRSL, aes(x = week, y = bprs, linetype = treatment, fill = treatment, shape = treatment, col=treatment)) +
  geom_point() +
  scale_shape_manual(values = c(1,4)) +
  scale_x_continuous(name = "Week", breaks = seq(0, 8, 1)) + scale_y_continuous(name = "BPRS-score") + theme(legend.position = "top")
```

The general trend seems to be downward in relation to time, that is the lower the measured symptoms the longer the treatment has progressed. But any obvious difference between the treatment groups is quite hard to make out.

Next we fit the BPRSL-data to a linear regression model, below a summary of the model using the BPRS-score as the response variable and the Treatment and Week variables as explanatories.

```{r}
BPRSL_reg <- lm(bprs ~ week + treatment, BPRSL)

summary(BPRSL_reg)
```

The coefficient of about 0,5 for treatment seems about right for the slight downward trend of the BPRS-scores across the weeks.

Next we have a look at a line plot illustrating the progress of the subjects over the course of the weeks. The subjects are separated by treatment groups.

```{r}
BPRSL %>%
  mutate(uID = paste(treatment,subject, sep="_")) %>%
  ggplot(., aes(x = week, y = bprs, group = uID)) +
  geom_line(aes(linetype = treatment)) +
  xlab("Weeks") +
  ylab("BPRS-score")
```

The line plot doesn't give any surprises in relation to the point plot above. Same here, the treatment group 2 can someplaces maybe be identified as having higher BPRS-scores but in general there's massive overlapping between the two groups.

Next, a scatterplot matrix of the original BPRS-data with BPRS-scores across the weeks.

```{r}
pairs(BPRS[,3:11])
```

Next we fit a random intercept model with Week and Treatment as explanatory variables and the BPRS-scores as response variable.

```{r}
library(lme4)

BPRS_ref <- lmer(bprs ~ week + treatment + (1 | subject), data = BPRSL, REML = FALSE)

summary(BPRS_ref)
```

Next we expand to a random intercept and random slope model.

```{r}
BPRS_ref1 <- lmer(bprs ~ week + treatment + (week | subject), data = BPRSL, REML = FALSE)

summary(BPRS_ref1)
```

Finally a random intercept and random slope model with multiplication of the explanatory variables.

```{r}
BPRS_ref2 <- lmer(bprs ~ (week*treatment) + week + treatment + (1 | subject), data = BPRSL, REML = FALSE)

summary(BPRS_ref2)
```

Now we can compare the observed BPRS-scores with the scores from the fitted model.

```{r}
p1 <- BPRSL %>%
  mutate(uID = paste(treatment,subject, sep="_")) %>%
  ggplot(., aes(x = week, y = bprs, group = uID)) +
  geom_line(aes(linetype = treatment)) +
  xlab("Weeks") +
  ylab("BPRS-score")

Fitted <- fitted(BPRS_ref2)
BPRSL$Fitted <- Fitted

p2 <- BPRSL %>%
  mutate(uID = paste(treatment,subject, sep="_")) %>%
  ggplot(., aes(x = week, y = Fitted, group = uID)) +
  geom_line(aes(linetype = treatment)) +
  xlab("Weeks") +
  ylab("Fitted BPRS-score")

p1
p2
```

As we can see, the fitted model could have done a better job. The plot of the fitted model is based on "predicted" values of BPRS for each test subject. But if we glance at the lower spectrum of the plot, the fitted model is quite off base. Towards the last week(s) the prediction homes in better on the actual observed values, but especially in the first one or two weeks and especially for the individuals with the lowest scores, the model is way off.
